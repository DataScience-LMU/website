---
title: "Data Science @ LMU Munich - Publications"
layout: textlay
excerpt: "Data Science @ LMU Munich - Publications"
sitemap: false
permalink: /publications/
---


# Publications

We try to keep our publications up to date on [Google Scholar](https://scholar.google.de/citations?user=_DYguksAAAAJ).

## Recent Notable Papers

* *Constrained Probabilistic Mask Learning for Task-specific Undersampled MRI Reconstruction* **WACV 2024** ([ArXiv](https://arxiv.org/abs/2305.16376))
* *Smoothing the Edges: A General Framework for Smooth Optimization in Sparse Regularization using Hadamard Overparametrization* ([ArXiv](https://arxiv.org/abs/2307.03571))
* *Towards Efficient MCMC Sampling in Bayesian Neural Networks by Exploiting Symmetry* **ECML 2023** ([ArXiv](https://arxiv.org/abs/2304.02902))
* *A New PHO-rmula for Improved Performance of Semi-Structured Networks* **ICML 2023** ([ArXiv](https://arxiv.org/abs/2306.00522))
* *Cascaded Latent Diffusion Models for High-Resolution Chest X-ray Synthesis* **PAKDD 2023** ([ArXiv](https://arxiv.org/abs/2303.11224))
* *Approximate Bayesian Inference with Stein Functional Variational Gradient Descent* **ICLR 2023** ([OpenReview](https://openreview.net/forum?id=a2-aoqmeYM4))
* *Frequentist Uncertainty Quantification in Semi-Structured Neural Networks* **AIStats 2023** ([MLR](https://proceedings.mlr.press/v206/dorigatti23a/dorigatti23a.pdf))
* *Semi-Structured Distributional Regression* **The American Statistician (2023)** ([ArXiv](https://arxiv.org/pdf/2002.05777.pdf))
* *Accelerated Componentwise Gradient Boosting using Efficient Data Representation and Momentum-based Optimization* **JCGS (2022)** ([ArXiv](https://arxiv.org/abs/2110.03513))
* *A Deep Learning Version of Hess & Brezowskys Classification of Gro√üwetterlagen over Europe: Projection of Future Changes in a CMIP6 Large Ensemble* **Environmental Research Letters (2022)** ([Uni Lib](https://epub.ub.uni-muenchen.de/93788/1/Mittermeier_2022_Environ._Res._Lett._17_084021.pdf))
* *Domain Adaptation for Time-Series Classification to Mitigate Covariate Shift* **ACM Multimedia 2022** ([ArXiv](https://arxiv.org/abs/2204.03342))


# Software

+ `deeptrafo` *Fitting Deep Conditional Transformation Models* on [CRAN](https://cran.r-project.org/web/packages/deeptrafo/index.html) and [Github](https://github.com/neural-structured-additive-learning/deeptrafo)
+ `safareg` *Structured Additive Factorization Regression* on [Github](https://github.com/neural-structured-additive-learning/safareg)
+ `deepregression` *Semi-Strutured Deep Distributional Regression* on [CRAN](https://cran.r-project.org/web/packages/deepregression/index.html) and [Github](https://github.com/neural-structured-additive-learning/deepregression/)
+ `mixdistreg` *Add-on package for deepregression to fit mixture families* on [Github](https://github.com/neural-structured-additive-learning/mixdistreg)
+ `selfmade`  *SELective inference For Mixed and ADditive model Estimators* on [CRAN](https://cran.r-project.org/web/packages/selfmade/index.html) and [Github](https://github.com/davidruegamer/selfmade/)
+ `FDboost`  *Boosting Functional Regression Models* on [CRAN](https://cran.r-project.org/web/packages/FDboost/index.html) and [Github](https://github.com/boost-R/FDboost)
+ `cAIC4`  *Conditional Akaike Information Criterion for 'lme4'* on [CRAN](https://cran.r-project.org/web/packages/cAIC4/index.html) and [Github](https://github.com/davidruegamer/cAIC4dev)
+ `iboost`  *Inference for Model-based Boosting* on [Github](https://github.com/davidruegamer/iboost)
+ `coinflibs`  *Conditional Inference after Likelihood-based Selection* on [Github](https://github.com/davidruegamer/coinflibs)
+ `effortless`  *Efficient operations on row-wise tensor product linked evaluations with special structures* on [Github](https://github.com/davidruegamer/effortless)
+ `MaCheX`  *Large scale collection of chest X-ray datasets* on [Github](https://github.com/saiboxx/machex)
+ `Cheff`  *Foundational diffusion model for chest X-ray synthesis* on [Github](https://github.com/saiboxx/chexray-diffusion)


&nbsp;
&nbsp;
